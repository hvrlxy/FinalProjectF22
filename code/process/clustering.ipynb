{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory:  /Users/hale/Desktop/NEU-CLASS/FinalProjectF22/code/process/../../\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import sklearn.cluster as cluster\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from generate_labels_summary import get_labels_synced_actigraphy_file, get_labels_columes, labels_type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Read the filtered actigraphy data with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = 10\n",
    "which_labels = 1\n",
    "labels_type = {1: \"PhysicalActivity\",\n",
    "                2: \"BehavioralPattern\",\n",
    "                3: \"HighLevelBehavioralPattern\",\n",
    "                4: \"Posture\"}\n",
    "\n",
    "subject_df = get_labels_synced_actigraphy_file(subject_id, which_labels, is_dominant_hand=True)\n",
    "subject_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all the columes except for the ones with stand, sit, walk, stair, cycling, sit, lying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the labels columes that do not contains stand, sit, staitr, cycling, sit, lying, run\n",
    "#first get the timestamp, and the features columns\n",
    "cols = subject_df.columns\n",
    "# print(cols)\n",
    "original_cols = [col for col in cols if col[0] == \"x\" or col[0] == \"y\" or col[0] == \"z\" or col == \"timestamp\"]\n",
    "# print(original_cols)\n",
    "new_subject_df = subject_df[original_cols]\n",
    "final_labels = []\n",
    "for labels in get_labels_columes(subject_df):\n",
    "    # if labels.lower() contains any of the following words, add it to the new df\n",
    "    kept_labels = [\"stand\", \"sit\", \"stair\", \"cycling\", \"sit\", \"lying\", \"run\"]\n",
    "    for words in kept_labels:\n",
    "        if words in labels.lower():\n",
    "            new_subject_df[labels] = subject_df[labels]\n",
    "            final_labels.append(labels)\n",
    "            break\n",
    "\n",
    "# remove all the rows that do not contain any labels\n",
    "new_subject_df = new_subject_df.dropna(axis=0, how=\"all\", subset=get_labels_columes(new_subject_df))\n",
    "new_subject_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of making each labels a columes, change the format so that the labels are concatenate into one big dataframe, with each features are represented as one columes and one \"class columes\" which indicate the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe which only contains the timestamp and features columns\n",
    "final_subject_df = pd.DataFrame()\n",
    "for label in final_labels:\n",
    "    label_df = new_subject_df[[col for col in new_subject_df.columns if col not in final_labels]]\n",
    "    label_df[label] = new_subject_df[label]\n",
    "    #drop all the row with value in the label colume is not 1\n",
    "    label_df = label_df[label_df[label] == 1]\n",
    "    # drop all other labels colume except the one we are working on\n",
    "    label_df = label_df[[col for col in label_df.columns if col not in final_labels or col == label]]\n",
    "    # add a class column and set it to the label\n",
    "    label_df[\"class\"] = label\n",
    "    # drop label colume\n",
    "    label_df = label_df[[col for col in label_df.columns if col != label]]\n",
    "    #  add label df to the final df\n",
    "    final_subject_df = final_subject_df.append(label_df)\n",
    "\n",
    "# print out the summary number of class\n",
    "print(final_subject_df[\"class\"].value_counts())\n",
    "final_subject_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining labels with stair in the name in final_subject-df\n",
    "final_subject_df[\"class\"] = final_subject_df[\"class\"].apply(lambda x: \"STAIR\" if \"stair\" in x.lower() else x)\n",
    "# combining labels with stand in the name in final_subject-df\n",
    "final_subject_df[\"class\"] = final_subject_df[\"class\"].apply(lambda x: \"STILL\" if \"still\" in x.lower() else x)\n",
    "# get the summary of class\n",
    "final_subject_df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the look of it, this seems to channel the summary labels files very well. I want to add one more columes to indicate the hour of the timestamp, since this might be improtant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one columes indicating the hour of the timestamp, in EDT time\n",
    "#first, we must convert timestamp to datetime (in EDT time)\n",
    "final_subject_df[\"hour\"] = pd.to_datetime(final_subject_df[\"timestamp\"], unit=\"s\")\n",
    "final_subject_df[\"hour\"] = final_subject_df[\"hour\"].apply(lambda x: x.hour)\n",
    "# put the hour colume in the front\n",
    "cols = final_subject_df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "final_subject_df = final_subject_df[cols]\n",
    "\n",
    "final_subject_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to use PCA to reduce the dimension of our data, and plot it the see the discriminality of the different labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data for clustering\n",
    "# first, remove the timestamp colume\n",
    "final_subject_df = final_subject_df[[col for col in final_subject_df.columns if col != \"timestamp\"]]\n",
    "# remove the class columes and save it to a variable\n",
    "class_df = final_subject_df[\"class\"]\n",
    "final_subject_df = final_subject_df[[col for col in final_subject_df.columns if col != \"class\"]]    \n",
    "# then, convert the dataframe to numpy array\n",
    "final_subject_df = final_subject_df.values\n",
    "# then, normalize the data\n",
    "final_subject_df = preprocessing.normalize(final_subject_df)\n",
    "# then, convert the numpy array to dataframe\n",
    "final_subject_df = pd.DataFrame(final_subject_df)\n",
    "final_subject_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(final_subject_df)\n",
    "pca_final_subject_df = pca.transform(final_subject_df)\n",
    "\n",
    "# add the class back to the dataframe\n",
    "pca_final_subject_df = pd.DataFrame(pca_final_subject_df)\n",
    "pca_final_subject_df[\"class\"] = class_df\n",
    "\n",
    "# plot the data\n",
    "plt.figure(figsize=(8, 8))\n",
    "for label in pca_final_subject_df[\"class\"].unique():\n",
    "    label_df = pca_final_subject_df[pca_final_subject_df[\"class\"] == label]\n",
    "    plt.scatter(label_df[0], label_df[1], label=label)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add class colume back to the final_subject-df\n",
    "final_subject_df = pd.DataFrame(final_subject_df)\n",
    "final_subject_df[\"class\"] = class_df\n",
    "#remove nan labels\n",
    "final_subject_df = final_subject_df.dropna(axis=0, how=\"any\", subset=[\"class\"])\n",
    "\n",
    "# let's try to train a classifier to predict the class\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# split the data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_subject_df[[col for col in final_subject_df.columns if col != \"class\"]], final_subject_df[\"class\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# train the model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# predict the class\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
