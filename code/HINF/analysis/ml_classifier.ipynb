{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer, fbeta_score\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"../../..\")\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data/PAAWS/HINF_results/ML_value/ml.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data from csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_dominant_hand</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "      <th>t6</th>\n",
       "      <th>t7</th>\n",
       "      <th>t8</th>\n",
       "      <th>t9</th>\n",
       "      <th>t10</th>\n",
       "      <th>is_awake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.636340e+09</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>133.897566</td>\n",
       "      <td>138.723742</td>\n",
       "      <td>11.607398</td>\n",
       "      <td>20.176750</td>\n",
       "      <td>15.028654</td>\n",
       "      <td>13.808494</td>\n",
       "      <td>8.592218</td>\n",
       "      <td>5.973276</td>\n",
       "      <td>219.127295</td>\n",
       "      <td>60.719584</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.636341e+09</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>186.119181</td>\n",
       "      <td>104.270434</td>\n",
       "      <td>123.303300</td>\n",
       "      <td>33.353866</td>\n",
       "      <td>7.082763</td>\n",
       "      <td>79.694083</td>\n",
       "      <td>27.139002</td>\n",
       "      <td>27.714479</td>\n",
       "      <td>10.839804</td>\n",
       "      <td>15.673297</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.636341e+09</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.137241</td>\n",
       "      <td>9.478856</td>\n",
       "      <td>14.606582</td>\n",
       "      <td>29.526991</td>\n",
       "      <td>23.313256</td>\n",
       "      <td>54.736681</td>\n",
       "      <td>356.012776</td>\n",
       "      <td>228.638837</td>\n",
       "      <td>15.498464</td>\n",
       "      <td>9.004995</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.636341e+09</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.861755</td>\n",
       "      <td>28.725396</td>\n",
       "      <td>21.522301</td>\n",
       "      <td>34.755128</td>\n",
       "      <td>13.680757</td>\n",
       "      <td>23.010703</td>\n",
       "      <td>65.102956</td>\n",
       "      <td>37.238526</td>\n",
       "      <td>40.971031</td>\n",
       "      <td>120.009205</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.636341e+09</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113.669381</td>\n",
       "      <td>24.312051</td>\n",
       "      <td>55.787079</td>\n",
       "      <td>32.075842</td>\n",
       "      <td>24.206239</td>\n",
       "      <td>36.009034</td>\n",
       "      <td>17.578392</td>\n",
       "      <td>120.446664</td>\n",
       "      <td>23.342901</td>\n",
       "      <td>21.418968</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111163</th>\n",
       "      <td>1.651773e+09</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.166969</td>\n",
       "      <td>29.261009</td>\n",
       "      <td>204.805835</td>\n",
       "      <td>145.493203</td>\n",
       "      <td>9.930581</td>\n",
       "      <td>37.620746</td>\n",
       "      <td>215.617256</td>\n",
       "      <td>139.099470</td>\n",
       "      <td>166.391553</td>\n",
       "      <td>249.366493</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111164</th>\n",
       "      <td>1.651773e+09</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>675.729349</td>\n",
       "      <td>477.644093</td>\n",
       "      <td>661.365728</td>\n",
       "      <td>627.166552</td>\n",
       "      <td>323.841812</td>\n",
       "      <td>238.286517</td>\n",
       "      <td>475.389594</td>\n",
       "      <td>558.661125</td>\n",
       "      <td>419.851758</td>\n",
       "      <td>86.814788</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111165</th>\n",
       "      <td>1.651773e+09</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>299.888626</td>\n",
       "      <td>438.333245</td>\n",
       "      <td>343.235316</td>\n",
       "      <td>393.861286</td>\n",
       "      <td>293.038422</td>\n",
       "      <td>407.391127</td>\n",
       "      <td>259.169468</td>\n",
       "      <td>161.635855</td>\n",
       "      <td>192.665703</td>\n",
       "      <td>320.127491</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111166</th>\n",
       "      <td>1.651773e+09</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>409.636119</td>\n",
       "      <td>281.254187</td>\n",
       "      <td>705.151593</td>\n",
       "      <td>400.213953</td>\n",
       "      <td>504.022807</td>\n",
       "      <td>486.839360</td>\n",
       "      <td>481.032165</td>\n",
       "      <td>370.752820</td>\n",
       "      <td>403.714479</td>\n",
       "      <td>588.956122</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111167</th>\n",
       "      <td>1.651774e+09</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>132.017036</td>\n",
       "      <td>40.085234</td>\n",
       "      <td>480.934627</td>\n",
       "      <td>457.385154</td>\n",
       "      <td>576.253420</td>\n",
       "      <td>346.392408</td>\n",
       "      <td>278.813294</td>\n",
       "      <td>35.383568</td>\n",
       "      <td>34.282769</td>\n",
       "      <td>25.503349</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111168 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           timestamp  user_id  is_dominant_hand          t1          t2  \\\n",
       "0       1.636340e+09     10.0               1.0  133.897566  138.723742   \n",
       "1       1.636341e+09     10.0               1.0  186.119181  104.270434   \n",
       "2       1.636341e+09     10.0               1.0   19.137241    9.478856   \n",
       "3       1.636341e+09     10.0               1.0    8.861755   28.725396   \n",
       "4       1.636341e+09     10.0               1.0  113.669381   24.312051   \n",
       "...              ...      ...               ...         ...         ...   \n",
       "111163  1.651773e+09     32.0               1.0   26.166969   29.261009   \n",
       "111164  1.651773e+09     32.0               1.0  675.729349  477.644093   \n",
       "111165  1.651773e+09     32.0               1.0  299.888626  438.333245   \n",
       "111166  1.651773e+09     32.0               1.0  409.636119  281.254187   \n",
       "111167  1.651774e+09     32.0               1.0  132.017036   40.085234   \n",
       "\n",
       "                t3          t4          t5          t6          t7  \\\n",
       "0        11.607398   20.176750   15.028654   13.808494    8.592218   \n",
       "1       123.303300   33.353866    7.082763   79.694083   27.139002   \n",
       "2        14.606582   29.526991   23.313256   54.736681  356.012776   \n",
       "3        21.522301   34.755128   13.680757   23.010703   65.102956   \n",
       "4        55.787079   32.075842   24.206239   36.009034   17.578392   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "111163  204.805835  145.493203    9.930581   37.620746  215.617256   \n",
       "111164  661.365728  627.166552  323.841812  238.286517  475.389594   \n",
       "111165  343.235316  393.861286  293.038422  407.391127  259.169468   \n",
       "111166  705.151593  400.213953  504.022807  486.839360  481.032165   \n",
       "111167  480.934627  457.385154  576.253420  346.392408  278.813294   \n",
       "\n",
       "                t8          t9         t10  is_awake  \n",
       "0         5.973276  219.127295   60.719584       1.0  \n",
       "1        27.714479   10.839804   15.673297       1.0  \n",
       "2       228.638837   15.498464    9.004995       1.0  \n",
       "3        37.238526   40.971031  120.009205       1.0  \n",
       "4       120.446664   23.342901   21.418968       1.0  \n",
       "...            ...         ...         ...       ...  \n",
       "111163  139.099470  166.391553  249.366493       1.0  \n",
       "111164  558.661125  419.851758   86.814788       1.0  \n",
       "111165  161.635855  192.665703  320.127491       1.0  \n",
       "111166  370.752820  403.714479  588.956122       1.0  \n",
       "111167   35.383568   34.282769   25.503349       1.0  \n",
       "\n",
       "[111168 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the csv file\n",
    "data_df = pd.read_csv(DATA_DIR)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.7351756180775106\n",
      "Average Balanced Accuracy: 0.6976496958691507\n",
      "Average F1 Score: 0.6060090210189399\n",
      "Average Precision: 0.7517745455126438\n",
      "Average Recall: 0.5076124500994543\n",
      "Average ROC AUC: 0.6976496958691507\n",
      "Average FPR: 0.11231305836115302\n"
     ]
    }
   ],
   "source": [
    "# initliaze the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# get the features, which is from t1 to t10\n",
    "features_cols = ['t1', 't2', 't3', 't4', 't5', 't6', 't7', 't8', 't9', 't10']\n",
    "\n",
    "# get the 10 fold cross validation\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "accuracy_lst = []\n",
    "precision_lst = []\n",
    "f1_lst = []\n",
    "recall_lst = []\n",
    "balanced_lst = []\n",
    "auroc_lst = []\n",
    "fpr_lst = []\n",
    "# loop through each fold\n",
    "for train_index, test_index in cv.split(data_df):\n",
    "    # get the training and testing data\n",
    "    train_df = data_df.iloc[train_index]\n",
    "    test_df = data_df.iloc[test_index]\n",
    "    \n",
    "    # get the X_train, y_train, X_test, y_test\n",
    "    X_train = train_df[features_cols]\n",
    "    y_train = train_df['is_awake']\n",
    "    X_test = test_df[features_cols]\n",
    "    y_test = test_df['is_awake']\n",
    "    \n",
    "    # scale the data\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # initialize the model\n",
    "    model = LogisticRegression()\n",
    "    # train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # get the prediction\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # add metrics to the list\n",
    "    accuracy_lst.append(accuracy_score(y_test, y_pred))\n",
    "    precision_lst.append(precision_score(y_test, y_pred))\n",
    "    f1_lst.append(f1_score(y_test, y_pred))\n",
    "    recall_lst.append(recall_score(y_test, y_pred))\n",
    "    balanced_lst.append(balanced_accuracy_score(y_test, y_pred))\n",
    "    auroc_lst.append(roc_auc_score(y_test, y_pred))\n",
    "    fpr_lst.append(confusion_matrix(y_test, y_pred)[0][1] / (confusion_matrix(y_test, y_pred)[0][1] + confusion_matrix(y_test, y_pred)[0][0]))\n",
    "    \n",
    "# print the average metrics\n",
    "print(\"Average Accuracy: {}\".format(np.mean(accuracy_lst)))\n",
    "print(\"Average Balanced Accuracy: {}\".format(np.mean(balanced_lst)))\n",
    "print(\"Average F1 Score: {}\".format(np.mean(f1_lst)))\n",
    "print(\"Average Precision: {}\".format(np.mean(precision_lst)))\n",
    "print(\"Average Recall: {}\".format(np.mean(recall_lst)))\n",
    "print(\"Average ROC AUC: {}\".format(np.mean(auroc_lst)))\n",
    "print(\"Average FPR: {}\".format(np.mean(fpr_lst)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guassian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.7351756180775106\n",
      "Average Balanced Accuracy: 0.6976496958691507\n",
      "Average F1 Score: 0.6060090210189399\n",
      "Average Precision: 0.7517745455126438\n",
      "Average Recall: 0.5076124500994543\n",
      "Average ROC AUC: 0.6976496958691507\n",
      "Average FPR: 0.11231305836115302\n"
     ]
    }
   ],
   "source": [
    "# initliaze the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# get the features, which is from t1 to t10\n",
    "features_cols = ['t1', 't2', 't3', 't4', 't5', 't6', 't7', 't8', 't9', 't10']\n",
    "\n",
    "# get the 10 fold cross validation\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "accuracy_lst = []\n",
    "precision_lst = []\n",
    "f1_lst = []\n",
    "recall_lst = []\n",
    "balanced_lst = []\n",
    "auroc_lst = []\n",
    "fpr_lst = []\n",
    "# loop through each fold\n",
    "for train_index, test_index in cv.split(data_df):\n",
    "    # get the training and testing data\n",
    "    train_df = data_df.iloc[train_index]\n",
    "    test_df = data_df.iloc[test_index]\n",
    "    \n",
    "    # get the X_train, y_train, X_test, y_test\n",
    "    X_train = train_df[features_cols]\n",
    "    y_train = train_df['is_awake']\n",
    "    X_test = test_df[features_cols]\n",
    "    y_test = test_df['is_awake']\n",
    "    \n",
    "    # scale the data\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # initialize the guassian naive bayes model\n",
    "    clf = GaussianNB()\n",
    "    # train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # get the prediction\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # add metrics to the list\n",
    "    accuracy_lst.append(accuracy_score(y_test, y_pred))\n",
    "    precision_lst.append(precision_score(y_test, y_pred))\n",
    "    f1_lst.append(f1_score(y_test, y_pred))\n",
    "    recall_lst.append(recall_score(y_test, y_pred))\n",
    "    balanced_lst.append(balanced_accuracy_score(y_test, y_pred))\n",
    "    auroc_lst.append(roc_auc_score(y_test, y_pred))\n",
    "    fpr_lst.append(confusion_matrix(y_test, y_pred)[0][1] / (confusion_matrix(y_test, y_pred)[0][1] + confusion_matrix(y_test, y_pred)[0][0]))\n",
    "    \n",
    "# print the average metrics\n",
    "print(\"Average Accuracy: {}\".format(np.mean(accuracy_lst)))\n",
    "print(\"Average Balanced Accuracy: {}\".format(np.mean(balanced_lst)))\n",
    "print(\"Average F1 Score: {}\".format(np.mean(f1_lst)))\n",
    "print(\"Average Precision: {}\".format(np.mean(precision_lst)))\n",
    "print(\"Average Recall: {}\".format(np.mean(recall_lst)))\n",
    "print(\"Average ROC AUC: {}\".format(np.mean(auroc_lst)))\n",
    "print(\"Average FPR: {}\".format(np.mean(fpr_lst)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.7351756180775106\n",
      "Average Balanced Accuracy: 0.6976496958691507\n",
      "Average F1 Score: 0.6060090210189399\n",
      "Average Precision: 0.7517745455126438\n",
      "Average Recall: 0.5076124500994543\n",
      "Average ROC AUC: 0.6976496958691507\n",
      "Average FPR: 0.11231305836115302\n"
     ]
    }
   ],
   "source": [
    "# initliaze the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# get the features, which is from t1 to t10\n",
    "features_cols = ['t1', 't2', 't3', 't4', 't5', 't6', 't7', 't8', 't9', 't10']\n",
    "\n",
    "# get the 10 fold cross validation\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "accuracy_lst = []\n",
    "precision_lst = []\n",
    "f1_lst = []\n",
    "recall_lst = []\n",
    "balanced_lst = []\n",
    "auroc_lst = []\n",
    "fpr_lst = []\n",
    "# loop through each fold\n",
    "for train_index, test_index in cv.split(data_df):\n",
    "    # get the training and testing data\n",
    "    train_df = data_df.iloc[train_index]\n",
    "    test_df = data_df.iloc[test_index]\n",
    "    \n",
    "    # get the X_train, y_train, X_test, y_test\n",
    "    X_train = train_df[features_cols]\n",
    "    y_train = train_df['is_awake']\n",
    "    X_test = test_df[features_cols]\n",
    "    y_test = test_df['is_awake']\n",
    "    \n",
    "    # scale the data\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # initialize the random forest model\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=3)\n",
    "    # train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # get the prediction\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # add metrics to the list\n",
    "    accuracy_lst.append(accuracy_score(y_test, y_pred))\n",
    "    precision_lst.append(precision_score(y_test, y_pred))\n",
    "    f1_lst.append(f1_score(y_test, y_pred))\n",
    "    recall_lst.append(recall_score(y_test, y_pred))\n",
    "    balanced_lst.append(balanced_accuracy_score(y_test, y_pred))\n",
    "    auroc_lst.append(roc_auc_score(y_test, y_pred))\n",
    "    fpr_lst.append(confusion_matrix(y_test, y_pred)[0][1] / (confusion_matrix(y_test, y_pred)[0][1] + confusion_matrix(y_test, y_pred)[0][0]))\n",
    "    \n",
    "# print the average metrics\n",
    "print(\"Average Accuracy: {}\".format(np.mean(accuracy_lst)))\n",
    "print(\"Average Balanced Accuracy: {}\".format(np.mean(balanced_lst)))\n",
    "print(\"Average F1 Score: {}\".format(np.mean(f1_lst)))\n",
    "print(\"Average Precision: {}\".format(np.mean(precision_lst)))\n",
    "print(\"Average Recall: {}\".format(np.mean(recall_lst)))\n",
    "print(\"Average ROC AUC: {}\".format(np.mean(auroc_lst)))\n",
    "print(\"Average FPR: {}\".format(np.mean(fpr_lst)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.7351756180775106\n",
      "Average Balanced Accuracy: 0.6976496958691507\n",
      "Average F1 Score: 0.6060090210189399\n",
      "Average Precision: 0.7517745455126438\n",
      "Average Recall: 0.5076124500994543\n",
      "Average ROC AUC: 0.6976496958691507\n",
      "Average FPR: 0.11231305836115302\n"
     ]
    }
   ],
   "source": [
    "# initliaze the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# get the features, which is from t1 to t10\n",
    "features_cols = ['t1', 't2', 't3', 't4', 't5', 't6', 't7', 't8', 't9', 't10']\n",
    "\n",
    "# get the 10 fold cross validation\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "accuracy_lst = []\n",
    "precision_lst = []\n",
    "f1_lst = []\n",
    "recall_lst = []\n",
    "balanced_lst = []\n",
    "auroc_lst = []\n",
    "fpr_lst = []\n",
    "# loop through each fold\n",
    "for train_index, test_index in cv.split(data_df):\n",
    "    # get the training and testing data\n",
    "    train_df = data_df.iloc[train_index]\n",
    "    test_df = data_df.iloc[test_index]\n",
    "    \n",
    "    # get the X_train, y_train, X_test, y_test\n",
    "    X_train = train_df[features_cols]\n",
    "    y_train = train_df['is_awake']\n",
    "    X_test = test_df[features_cols]\n",
    "    y_test = test_df['is_awake']\n",
    "    \n",
    "    # scale the data\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # initialize the MLP model with 3 hidden layers with 10 neurons each\n",
    "    clf = MLPClassifier(activation= 'relu', alpha= 0.05, hidden_layer_sizes= (10, 30, 10), learning_rate= 'adaptive', solver= 'adam')\n",
    "    # train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # get the prediction\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # add metrics to the list\n",
    "    accuracy_lst.append(accuracy_score(y_test, y_pred))\n",
    "    precision_lst.append(precision_score(y_test, y_pred))\n",
    "    f1_lst.append(f1_score(y_test, y_pred))\n",
    "    recall_lst.append(recall_score(y_test, y_pred))\n",
    "    balanced_lst.append(balanced_accuracy_score(y_test, y_pred))\n",
    "    auroc_lst.append(roc_auc_score(y_test, y_pred))\n",
    "    fpr_lst.append(confusion_matrix(y_test, y_pred)[0][1] / (confusion_matrix(y_test, y_pred)[0][1] + confusion_matrix(y_test, y_pred)[0][0]))\n",
    "    \n",
    "# print the average metrics\n",
    "print(\"Average Accuracy: {}\".format(np.mean(accuracy_lst)))\n",
    "print(\"Average Balanced Accuracy: {}\".format(np.mean(balanced_lst)))\n",
    "print(\"Average F1 Score: {}\".format(np.mean(f1_lst)))\n",
    "print(\"Average Precision: {}\".format(np.mean(precision_lst)))\n",
    "print(\"Average Recall: {}\".format(np.mean(recall_lst)))\n",
    "print(\"Average ROC AUC: {}\".format(np.mean(auroc_lst)))\n",
    "print(\"Average FPR: {}\".format(np.mean(fpr_lst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8329135558154178\n",
      "Balanced Accuracy: 0.8364740307335514\n",
      "F1 Score: 0.8054464519507725\n",
      "Precision: 0.7612353989309047\n",
      "Recall: 0.8551095296341599\n",
      "ROC AUC: 0.8364740307335514\n",
      "FPR: 0.18216146816705686\n",
      "Confusion Matrix: [[10829  2412]\n",
      " [ 1303  7690]]\n"
     ]
    }
   ],
   "source": [
    "# create a scorer function that use fbeta_score as the metric\n",
    "sc_fn = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "# grid search for the best parameters\n",
    "mlp_params = {\n",
    "    'hidden_layer_sizes': [(10,30,10)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.05],\n",
    "    'learning_rate': ['adaptive'],\n",
    "}\n",
    "clf = GridSearchCV(MLPClassifier(max_iter=1000), mlp_params, n_jobs=-1, cv=10, scoring='precision')\n",
    "\n",
    "# get the features, which is from t1 to t10\n",
    "features_cols = ['t1', 't2', 't3', 't4', 't5', 't6', 't7', 't8', 't9', 't10']\n",
    "# get the X and y\n",
    "X = data_df[features_cols]\n",
    "y = data_df['is_awake']\n",
    "\n",
    "#get X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#print the best parameters\n",
    "clf.best_params_\n",
    "\n",
    "# get the prediction\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the metrics\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Balanced Accuracy: {}\".format(balanced_accuracy_score(y_test, y_pred)))\n",
    "print(\"F1 Score: {}\".format(f1_score(y_test, y_pred)))\n",
    "print(\"Precision: {}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {}\".format(recall_score(y_test, y_pred)))\n",
    "print(\"ROC AUC: {}\".format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"FPR: {}\".format(confusion_matrix(y_test, y_pred)[0][1] / (confusion_matrix(y_test, y_pred)[0][1] + confusion_matrix(y_test, y_pred)[0][0])))\n",
    "print(\"Confusion Matrix: {}\".format(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.05,\n",
       " 'hidden_layer_sizes': (10, 30, 10),\n",
       " 'learning_rate': 'adaptive',\n",
       " 'solver': 'adam'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
